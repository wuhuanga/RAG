
import json
import logging
from typing import Any, Coroutine
from rich.logging import RichHandler
from langchain_litellm import ChatLiteLLM
from vector.prompts import PromptTemplate

logger = logging.getLogger("triple_extractor")
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    datefmt="[%X]",
    handlers=[RichHandler(rich_tracebacks=True, show_time=False, markup=True)],
)

def extract_triples(input_txt_path: str, output_json_path: str):
    with open(input_txt_path, "r", encoding="utf-8") as f:
        content = f.read()

    logging.basicConfig(
        level=logging.INFO,
        format="%(message)s",
        datefmt="[%X]",
        handlers=[RichHandler(rich_tracebacks=True, show_time=False, markup=True)],
    )
    llm = ChatLiteLLM(
        model="deepseek/deepseek-chat",
        temperature=0.7,
    )
    # FIX: Add 'await' here to get the actual result, not the coroutine.
    result = extract_requirement_triples(llm=llm, content=content)
    with open(output_json_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=4)

# --- åŠ è½½ txt æ–‡ä»¶å¹¶åˆ†æ®µ ---
def split_paragraphs(content: str) -> list[str]:
    paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
    return paragraphs


def extract_triples_from_paragraphs(
    llm: ChatLiteLLM,
    p1: str,
    p2: str,
    p3: str,
    p4: str,
    logger: logging.Logger,
) -> str:
    """
    ä½¿ç”¨ LLM ä»å››ä¸ªæ®µè½ä¸­æå–ä¸‰å…ƒç»„ã€‚
    Args:
        p1, p2, p3, p4 (str): å››ä¸ªæ®µè½æ–‡æœ¬
    Returns:
        str: LLM è¿”å›çš„ JSON æ ¼å¼å­—ç¬¦ä¸²
    """
    prompt = PromptTemplate(
        input_variables=["p1", "p2", "p3", "p4"], template=triple_prompt_template
    ).format(p1=p1, p2=p2, p3=p3, p4=p4)
    logger.info(f"ğŸ§  æ­£åœ¨å¤„ç†æ®µè½ï¼š\n{p1}\n{p2}\n{p3}\n{p4}")
    response = llm.invoke(prompt)
    if not response.content:
        logger.error("âŒ LLM å“åº”å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–è¾“å…¥æ®µè½ã€‚")
        return ""
    return str(response.content)


# --- ä¸»æµç¨‹ï¼ˆä¿®æ”¹æ»‘åŠ¨çª—å£ä¸º4æ®µï¼Œæ­¥é•¿3ï¼‰ ---
def extract_requirement_triples(
    llm: ChatLiteLLM,
    content: str,
    window_size=4,
    step=3,
) -> dict:
    """
    ä»è¾“å…¥æ–‡æœ¬ä¸­æå–éœ€æ±‚ç›¸å…³çš„ä¸‰å…ƒç»„ï¼Œå¹¶è¿”å› JSON ã€‚
    Args:
        content (str): è¾“å…¥æ–‡æœ¬æ–‡ä»¶å†…å®¹
        window_size (int): çª—å£å¤§å°ï¼Œé»˜è®¤ä¸º4æ®µ
        step (int): æ­¥é•¿ï¼Œé»˜è®¤ä¸º3æ®µ
    """
    paragraphs = split_paragraphs(content)
    output_triples = []

    tasks: list[Coroutine[Any, Any, str]] = []
    total_windows = (len(paragraphs) - window_size) // step + 1

    for i in range(total_windows):
        start_idx = i * step
        window_paragraphs = paragraphs[start_idx : start_idx + window_size]

        # ç¡®ä¿æœ‰4æ®µ
        if len(window_paragraphs) < window_size:
            break

        tasks.append(
            extract_triples_from_paragraphs(
                llm=llm,
                p1=window_paragraphs[0],
                p2=window_paragraphs[1],
                p3=window_paragraphs[2],
                p4=window_paragraphs[3],
                logger=logger,
            )
        )

    results = await asyncio.gather(*tasks)

    for i, result in enumerate(results):
        try:
            result_json = json.loads(result)
        except json.JSONDecodeError:
            logger.error(f"âŒ JSON è§£æå¤±è´¥ï¼š{result}")
            continue

        triples = result_json.get("triples", [])  # æ³¨æ„è¿™é‡Œç”¨ "triples"
        output_triples.extend(triples)
        logger.info(f"âœ… å·²å¤„ç†çª—å£ {i + 1}/{total_windows}")

    logger.info(f"ğŸ‰ æå–å®Œæˆï¼Œå…±æå–ä¸‰å…ƒç»„æ•°: {len(output_triples)}")
    return {"triples": output_triples}